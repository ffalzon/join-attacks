.\section{Discussion}

\heading{Re-thinking Security.}
Standard security models in the MPC literature do not explicitly account for inference attacks arising from functionality outputs. Such attacks are often handled only indirectly, for example, through set-size thresholds. However, our analysis of $\calF_{\PSU}$, $\calF_{\PSUCA}$, and Meta's multi-key private matching functionality $\calF_{\LMKPM}$, together with prior work~\cite{USENIX:GHLWJL22,NDSS:JiaDuYan24,USENIX:FalTan25,USENIX:ZinCaoGre23}, underscores the need for a more systematic treatment of MPC protocol security. The functionality outputs should be explicitly incorporated into the security model. Failing to do so results in weak input privacy guarantees: in the worst case, a single query may suffice to partially or even fully recover another party's input.

\heading{Mitigations.}
Simple mitigations such as rate limiting can help against attacks that require $\omega(1)$ queries (e.g., our search-tree attacks and prior work~\cite{USENIX:GHLWJL22,NDSS:JiaDuYan24,USENIX:FalTan25}). However, two concerns arise. First, attacks typically improve over time, so only information-theoretic query lower bounds---and not the current best-known attack---should inform ``query budgets.'' Second, rate limits can be circumvented via Sybil attacks, which are often outside the protocol threat model but represent a very real risk.

To that end, we should look to more holistic mitigation techniques that restrict inputs or add noise to outputs. For example, ACORNS~\cite{USENIX:BGLLMR23} use range proofs to ensure that inputs are within the specified input domain. 
Goel et al. introduced PICS~\cite{USENIX:GMVS26}, a PSI framework in which protocol participants must first publicly commit to their input sets. The malciously-secure PSI protocol is augmented with zero-knowledge proofs to ensure that the computation is consistent with the committed inputs across multiple executions. 
%De Cristofaro and Tsudik~\cite{FC:DeCTsu10} introduced Authorized PSI in which each element in the client set must be authorized (signed) by some recognized and mutually trusted authority. 
%However, when inputs change (e.g., a user is added to a database), a fresh commitment must be computed, so inputs must change infrequently or remain static. 
%The authors highlight applications that tolerate this limitation, such as Apple's CSAM detection system~\cite{AppleCSAM}.

Differential Privacy (DP)~\cite{TCC:DMNS06} provides a formal way to quantify information leakage about inputs. Differentially private set operations have already been proposed~\cite{EUROSP:KKLNSSBSOK20}, as well as a differentially private record-matching functionality~\cite{DP-Match}, have already been proposed. Care must be taken that the correct parameters and query budgets are selected. Indeed, some of the attacks against PSI-CA in~\cite{NDSS:JiaDuYan24} were evaluated against a differentially private PSI-CA variant and were found to remain effective despite DP. 


\heading{Looking Towards Deployment.}
Recent works have sought to extend two-party joins to multiple parties~\cite{CCS:MohRinRos20,PoPETS:LehMouSid26} and the delegated compute setting~\cite{PoPETS:MMTSBC24}; such variants typically rely on a non-collusion assumptios between parties. At the same time, we observe growing adoption of MPC technologies by large organizations (e.g., Google's Private Join and Compute~\cite{EuroSP:IKNPSS20}). 
%This raises concerns about users' privacy expectations, especially since attacks that leverage adversarially chosen inputs are often left unaddressed.

This leads to a critical question: if attacks that leverage adversarially chosen inputs are within scope, in which application scenarios do they genuinely not arise? The intended scope and trust assumptions (e.g., non-collusion) should be made explicit at the time of proposal; otherwise, security proofs risk having limited practical relevance and may be misapplied in unintended settings. In practice, non-collusion assumptions may fail---for example, under subpoena power, regulatory pressure, or single-administrator access---leading to risks similar to those identified in our analysis. Clearly communicating these assumptions and their implications is therefore essential for responsible deployment and for avoiding a false sense of privacy among users.


